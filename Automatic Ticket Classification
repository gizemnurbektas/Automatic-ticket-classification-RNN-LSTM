# -*- coding: utf-8 -*-
"""Automatic Ticket Classification.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/12tKiDZbQAtqKH5dBw036lebfPVXR1d7Z
"""

import pandas as pd
import numpy as np
import re,string
import matplotlib.pyplot as plt

from collections import Counter

import nltk
nltk.download('stopwords')
from nltk.corpus import stopwords
from nltk.tokenize import word_tokenize



from google.colab import files
uploaded = files.upload()

df = pd.read_json("complaints-2021-05-14_08_16.json")
df.head()

df.info()

print("Shape:",df.shape)
print("Columns:",df.columns)
print("Index:",df.index)

df.isnull().sum()

print(df.head())

print(df.columns)

import json

df["_source"] = df["_source"].apply(lambda x: json.loads(x) if isinstance(x, str) else x)

# Normalleştir (içindeki alanları ayrı kolon yapar)
df_expanded = pd.json_normalize(df["_source"])

# Orijinal dataframe ile birleştir
df_final = pd.concat([df.drop(columns=["_source"]), df_expanded], axis=1)

print(df_final.head())
print(df_final.columns)

with open("complaints-2021-05-14_08_16.json", "r", encoding="utf-8") as f:
    for i in range(5):
        print(f.readline())

# Nested kolonları açma
df_expanded = pd.json_normalize(df["_source"])

# Hangi kolonlar geldi bakalım
print(df_expanded.columns.tolist())

# İlgili kolonları seçme
data = df_expanded[["complaint_what_happened", "product", "sub_product"]].copy()
data.head()

output_path = "filtered_complaints.json"
data.to_json(output_path, orient="records", force_ascii=False, indent=4)
print("JSON dosyası kaydedildi:", output_path)

from google.colab import files
files.download(output_path)

data = df_expanded[["complaint_what_happened", "product", "sub_product"]].copy()

data = data.rename(columns={
    "complaint_what_happened": "text",
    "product": "product",
    "sub_product": "sub_product"
})

data.head()

# Eksik sayıları ve oranları
na_counts = data.isna().sum().sort_values(ascending=False)
na_ratio = (data.isna().mean()*100).sort_values(ascending=False)
eda_na = pd.DataFrame({'missing_count': na_counts, 'missing_%': na_ratio.round(2)})
eda_na

data['text_len'] = data['text'].astype(str).str.len()
shorts = (data['text_len'] < 10).sum()
print(f"Çok kısa metin (<10 char) sayısı: {shorts}")

import matplotlib.pyplot as plt

plt.figure(figsize=(10,6))
plt.hist(data['text_len'], bins=100, edgecolor='black')  # Histogramı kendimiz çizelim
plt.title('Metin Uzunluğu Dağılımı')
plt.xlabel('Karakter sayısı')
plt.ylabel('Frekans')
plt.show()

top_products = data['product'].value_counts()
plt.figure(figsize=(8,4))
top_products.plot(kind='bar')
plt.title('Ürün Kategorileri')
plt.xlabel('product')
plt.ylabel('Adet')
plt.xticks(rotation=90)
plt.tight_layout()
plt.show()

top_sub = data['sub_product'].value_counts()
plt.figure(figsize=(8,4))
top_sub.plot(kind='bar')
plt.title('Alt Ürün Kategorileri ')
plt.xlabel('sub_product')
plt.ylabel('Adet')
plt.xticks(rotation=90, ha='right')
plt.tight_layout()
plt.show()

group_stats = data.groupby('product')['text_len'].agg(['count', 'mean', 'median']).sort_values('count', ascending=False).head(10)
group_stats

group_stats = data.groupby('sub_product')['text_len'].agg(['count', 'mean', 'median']).sort_values('count', ascending=False).head(10)
group_stats

















